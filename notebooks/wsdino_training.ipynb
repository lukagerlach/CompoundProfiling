{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddcdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybbbc import BBBC021\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.load_model import MODEL_NAMES\n",
    "from training.wsdino_resnet_train import (\n",
    "    BBBC021WeakLabelDataset,\n",
    "    get_resnet50,\n",
    "    dino_loss,\n",
    "    update_teacher\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd0c63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 12\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "epochs = 10  # reduce for notebook\n",
    "momentum = 0.996\n",
    "temperature = 0.07\n",
    "save_path = \"./resnet_wsdino.pth\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the preprocessed BBBC021 dataset using pybbbc,\n",
    "# pointing to the processed HDF5 dataset on disk\n",
    "bbbc = BBBC021(root_path=\"/scratch/cv-course2025/group8/processed\")\n",
    "\n",
    "# Define a torchvision transform: resize all images to 224x224 and convert to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Wrap the BBBC021 dataset into a PyTorch-compatible Dataset,\n",
    "# filtering out samples with 'null' MoA and applying transforms\n",
    "dataset = BBBC021WeakLabelDataset(bbbc, transform)\n",
    "\n",
    "# Create a DataLoader for batching and shuffling the dataset during training\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize the student ResNet-50 model with a classification head\n",
    "# The model type is BASE_RESNET (ImageNet-pretrained)\n",
    "student = get_resnet50(num_classes, MODEL_NAMES.BASE_RESNET)\n",
    "\n",
    "# Initialize the teacher model with the same architecture and weights as the student\n",
    "teacher = get_resnet50(num_classes, MODEL_NAMES.BASE_RESNET)\n",
    "teacher.load_state_dict(student.state_dict())  # synchronize weights\n",
    "\n",
    "# Freeze all parameters in the teacher so it won't be updated via gradient descent\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Set up the optimizer (Adam) to update only the student model parameters\n",
    "optimizer = torch.optim.Adam(student.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f2c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    student.train()  # Set the student model to training mode\n",
    "    total_loss = 0.0  # Accumulator for total loss in this epoch\n",
    "\n",
    "    # Iterate over each batch in the dataloader with a progress bar\n",
    "    for imgs, labels in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "        # Move input images and labels to GPU or CPU depending on `device`\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass through the student model\n",
    "        student_out = student(imgs)\n",
    "\n",
    "        # Forward pass through the teacher model (no gradients needed)\n",
    "        with torch.no_grad():\n",
    "            teacher_out = teacher(imgs)\n",
    "\n",
    "        # Compute DINO distillation loss between student and teacher outputs\n",
    "        loss = dino_loss(student_out, teacher_out)\n",
    "\n",
    "        # Backpropagation step\n",
    "        optimizer.zero_grad()     # Clear existing gradients\n",
    "        loss.backward()           # Compute gradients\n",
    "        optimizer.step()          # Update student model weights\n",
    "\n",
    "        # Update teacher weights using exponential moving average of student weights\n",
    "        update_teacher(student, teacher, momentum)\n",
    "\n",
    "        # Accumulate the batch loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Compute and print the average loss for the epoch\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}: Avg Loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), save_path)\n",
    "print(f\"Model saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
